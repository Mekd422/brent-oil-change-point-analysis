{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Brent Oil Price Change Point Analysis\n",
        "\n",
        "This notebook performs Bayesian change point detection on Brent oil prices to identify structural breaks and associate them with major geopolitical and economic events."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Loading and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (14, 6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load Brent oil price data\n",
        "df_prices = pd.read_csv('../data/brent_prices.csv')\n",
        "\n",
        "# Convert Date column to datetime\n",
        "# Handle the format '20-May-87'\n",
        "df_prices['Date'] = pd.to_datetime(df_prices['Date'], format='%d-%b-%y')\n",
        "\n",
        "# Sort by date\n",
        "df_prices = df_prices.sort_values('Date').reset_index(drop=True)\n",
        "\n",
        "print(f\"Data shape: {df_prices.shape}\")\n",
        "print(f\"Date range: {df_prices['Date'].min()} to {df_prices['Date'].max()}\")\n",
        "print(f\"Price range: ${df_prices['Price'].min():.2f} to ${df_prices['Price'].max():.2f}\")\n",
        "df_prices.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load events data\n",
        "df_events = pd.read_csv('../data/events.csv')\n",
        "df_events['Date'] = pd.to_datetime(df_events['Date'])\n",
        "df_events = df_events.sort_values('Date').reset_index(drop=True)\n",
        "\n",
        "print(f\"Number of events: {len(df_events)}\")\n",
        "df_events.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot raw price series\n",
        "plt.figure(figsize=(16, 6))\n",
        "plt.plot(df_prices['Date'], df_prices['Price'], linewidth=0.8, alpha=0.7)\n",
        "plt.title('Brent Oil Price Time Series (1987-2022)', fontsize=16, fontweight='bold')\n",
        "plt.xlabel('Date', fontsize=12)\n",
        "plt.ylabel('Price (USD per barrel)', fontsize=12)\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Add event markers\n",
        "for _, event in df_events.iterrows():\n",
        "    plt.axvline(x=event['Date'], color='red', linestyle='--', alpha=0.5, linewidth=1)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate log returns for stationarity analysis\n",
        "df_prices['Log_Price'] = np.log(df_prices['Price'])\n",
        "df_prices['Log_Returns'] = df_prices['Log_Price'].diff()\n",
        "df_prices = df_prices.dropna().reset_index(drop=True)\n",
        "\n",
        "# Plot log returns\n",
        "plt.figure(figsize=(16, 6))\n",
        "plt.plot(df_prices['Date'], df_prices['Log_Returns'], linewidth=0.5, alpha=0.7)\n",
        "plt.title('Brent Oil Log Returns (Stationarity Analysis)', fontsize=16, fontweight='bold')\n",
        "plt.xlabel('Date', fontsize=12)\n",
        "plt.ylabel('Log Returns', fontsize=12)\n",
        "plt.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Stationarity test\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "\n",
        "# Test on prices\n",
        "result_prices = adfuller(df_prices['Price'].dropna())\n",
        "print(\"ADF Test on Prices:\")\n",
        "print(f\"ADF Statistic: {result_prices[0]:.4f}\")\n",
        "print(f\"p-value: {result_prices[1]:.4f}\")\n",
        "print(f\"Is Stationary: {result_prices[1] < 0.05}\")\n",
        "print()\n",
        "\n",
        "# Test on log returns\n",
        "result_returns = adfuller(df_prices['Log_Returns'].dropna())\n",
        "print(\"ADF Test on Log Returns:\")\n",
        "print(f\"ADF Statistic: {result_returns[0]:.4f}\")\n",
        "print(f\"p-value: {result_returns[1]:.4f}\")\n",
        "print(f\"Is Stationary: {result_returns[1] < 0.05}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Rolling volatility\n",
        "window = 30  # 30-day rolling window\n",
        "df_prices['Rolling_Volatility'] = df_prices['Log_Returns'].rolling(window=window).std() * np.sqrt(252)\n",
        "\n",
        "plt.figure(figsize=(16, 6))\n",
        "plt.plot(df_prices['Date'], df_prices['Rolling_Volatility'], linewidth=1)\n",
        "plt.title(f'Rolling Volatility ({window}-day window, annualized)', fontsize=16, fontweight='bold')\n",
        "plt.xlabel('Date', fontsize=12)\n",
        "plt.ylabel('Volatility', fontsize=12)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Bayesian Change Point Model with PyMC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pymc as pm\n",
        "import arviz as az\n",
        "\n",
        "# Prepare data for modeling\n",
        "# We'll model the price levels (not returns) to detect mean shifts\n",
        "prices = df_prices['Price'].values\n",
        "n = len(prices)\n",
        "time_index = np.arange(n)\n",
        "\n",
        "print(f\"Number of observations: {n}\")\n",
        "print(f\"Price mean: ${prices.mean():.2f}\")\n",
        "print(f\"Price std: ${prices.std():.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build the Bayesian Change Point Model\n",
        "with pm.Model() as change_point_model:\n",
        "    # Switch point (tau) - discrete uniform prior over all possible days\n",
        "    tau = pm.DiscreteUniform(\"tau\", lower=1, upper=n-1)\n",
        "    \n",
        "    # Before and after mean parameters\n",
        "    # Use informative priors based on data\n",
        "    mu_before = pm.Normal(\"mu_before\", mu=prices.mean(), sigma=prices.std())\n",
        "    mu_after = pm.Normal(\"mu_after\", mu=prices.mean(), sigma=prices.std())\n",
        "    \n",
        "    # Standard deviation (assumed constant for simplicity)\n",
        "    sigma = pm.HalfNormal(\"sigma\", sigma=prices.std())\n",
        "    \n",
        "    # Switch function to select the correct mean based on tau\n",
        "    mu = pm.math.switch(time_index < tau, mu_before, mu_after)\n",
        "    \n",
        "    # Likelihood - Normal distribution\n",
        "    likelihood = pm.Normal(\"likelihood\", mu=mu, sigma=sigma, observed=prices)\n",
        "    \n",
        "    # Sample from posterior\n",
        "    trace = pm.sample(2000, tune=1000, return_inferencedata=True, random_seed=42)\n",
        "\n",
        "print(\"Sampling complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Model Diagnostics and Convergence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check convergence\n",
        "summary = az.summary(trace)\n",
        "print(\"Model Summary:\")\n",
        "print(summary)\n",
        "print(\"\\nR-hat values close to 1.0 indicate good convergence.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot trace plots\n",
        "az.plot_trace(trace, var_names=['tau', 'mu_before', 'mu_after', 'sigma'])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Change Point Identification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract posterior distribution of tau\n",
        "tau_samples = trace.posterior['tau'].values.flatten()\n",
        "\n",
        "# Plot posterior distribution of change point\n",
        "plt.figure(figsize=(14, 6))\n",
        "plt.hist(tau_samples, bins=50, alpha=0.7, edgecolor='black')\n",
        "plt.axvline(tau_samples.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {int(tau_samples.mean())}')\n",
        "plt.axvline(np.median(tau_samples), color='green', linestyle='--', linewidth=2, label=f'Median: {int(np.median(tau_samples))}')\n",
        "plt.xlabel('Change Point Index (tau)', fontsize=12)\n",
        "plt.ylabel('Frequency', fontsize=12)\n",
        "plt.title('Posterior Distribution of Change Point (tau)', fontsize=16, fontweight='bold')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Convert to dates\n",
        "most_likely_tau = int(np.median(tau_samples))\n",
        "change_point_date = df_prices.iloc[most_likely_tau]['Date']\n",
        "print(f\"Most likely change point index: {most_likely_tau}\")\n",
        "print(f\"Most likely change point date: {change_point_date.strftime('%Y-%m-%d')}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot change point on price series\n",
        "plt.figure(figsize=(16, 6))\n",
        "plt.plot(df_prices['Date'], df_prices['Price'], linewidth=0.8, alpha=0.7, label='Brent Oil Price')\n",
        "plt.axvline(x=change_point_date, color='red', linestyle='--', linewidth=2, label=f'Detected Change Point: {change_point_date.strftime(\"%Y-%m-%d\")}')\n",
        "\n",
        "# Add event markers\n",
        "for _, event in df_events.iterrows():\n",
        "    plt.axvline(x=event['Date'], color='orange', linestyle=':', alpha=0.5, linewidth=1)\n",
        "\n",
        "plt.title('Brent Oil Prices with Detected Change Point', fontsize=16, fontweight='bold')\n",
        "plt.xlabel('Date', fontsize=12)\n",
        "plt.ylabel('Price (USD per barrel)', fontsize=12)\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Impact Quantification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract posterior distributions of before/after parameters\n",
        "mu_before_samples = trace.posterior['mu_before'].values.flatten()\n",
        "mu_after_samples = trace.posterior['mu_after'].values.flatten()\n",
        "sigma_samples = trace.posterior['sigma'].values.flatten()\n",
        "\n",
        "# Plot posterior distributions\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "axes[0].hist(mu_before_samples, bins=50, alpha=0.7, edgecolor='black', color='blue')\n",
        "axes[0].axvline(mu_before_samples.mean(), color='red', linestyle='--', linewidth=2)\n",
        "axes[0].set_xlabel('Mean Before Change Point (USD)', fontsize=11)\n",
        "axes[0].set_ylabel('Frequency', fontsize=11)\n",
        "axes[0].set_title(f'Posterior: μ₁ (Before)\\nMean: ${mu_before_samples.mean():.2f}', fontsize=12, fontweight='bold')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "axes[1].hist(mu_after_samples, bins=50, alpha=0.7, edgecolor='black', color='green')\n",
        "axes[1].axvline(mu_after_samples.mean(), color='red', linestyle='--', linewidth=2)\n",
        "axes[1].set_xlabel('Mean After Change Point (USD)', fontsize=11)\n",
        "axes[1].set_ylabel('Frequency', fontsize=11)\n",
        "axes[1].set_title(f'Posterior: μ₂ (After)\\nMean: ${mu_after_samples.mean():.2f}', fontsize=12, fontweight='bold')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "axes[2].hist(sigma_samples, bins=50, alpha=0.7, edgecolor='black', color='purple')\n",
        "axes[2].axvline(sigma_samples.mean(), color='red', linestyle='--', linewidth=2)\n",
        "axes[2].set_xlabel('Standard Deviation (USD)', fontsize=11)\n",
        "axes[2].set_ylabel('Frequency', fontsize=11)\n",
        "axes[2].set_title(f'Posterior: σ\\nMean: ${sigma_samples.mean():.2f}', fontsize=12, fontweight='bold')\n",
        "axes[2].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate impact metrics\n",
        "mean_before = mu_before_samples.mean()\n",
        "mean_after = mu_after_samples.mean()\n",
        "absolute_change = mean_after - mean_before\n",
        "percentage_change = (absolute_change / mean_before) * 100\n",
        "\n",
        "# Calculate credible intervals (95%)\n",
        "ci_before = np.percentile(mu_before_samples, [2.5, 97.5])\n",
        "ci_after = np.percentile(mu_after_samples, [2.5, 97.5])\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"IMPACT QUANTIFICATION\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nChange Point Date: {change_point_date.strftime('%Y-%m-%d')}\")\n",
        "print(f\"\\nBefore Change Point:\")\n",
        "print(f\"  Mean Price: ${mean_before:.2f}\")\n",
        "print(f\"  95% Credible Interval: [${ci_before[0]:.2f}, ${ci_before[1]:.2f}]\")\n",
        "print(f\"\\nAfter Change Point:\")\n",
        "print(f\"  Mean Price: ${mean_after:.2f}\")\n",
        "print(f\"  95% Credible Interval: [${ci_after[0]:.2f}, ${ci_after[1]:.2f}]\")\n",
        "print(f\"\\nImpact:\")\n",
        "print(f\"  Absolute Change: ${absolute_change:.2f}\")\n",
        "print(f\"  Percentage Change: {percentage_change:.2f}%\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Event Association"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find events near the change point\n",
        "time_window_days = 90  # Look for events within 90 days\n",
        "\n",
        "change_point_datetime = pd.to_datetime(change_point_date)\n",
        "\n",
        "# Calculate time differences\n",
        "df_events['Days_Diff'] = (df_events['Date'] - change_point_datetime).dt.days.abs()\n",
        "nearby_events = df_events[df_events['Days_Diff'] <= time_window_days].sort_values('Days_Diff')\n",
        "\n",
        "print(f\"Events within {time_window_days} days of detected change point:\")\n",
        "print(\"=\" * 80)\n",
        "if len(nearby_events) > 0:\n",
        "    for _, event in nearby_events.iterrows():\n",
        "        print(f\"\\nEvent: {event['Event']}\")\n",
        "        print(f\"Date: {event['Date'].strftime('%Y-%m-%d')}\")\n",
        "        print(f\"Days from change point: {int(event['Days_Diff'])}\")\n",
        "        print(f\"Category: {event['Category']}\")\n",
        "        print(f\"Impact Level: {event['Impact_Level']}\")\n",
        "        print(f\"Description: {event['Description']}\")\n",
        "        print(\"-\" * 80)\n",
        "else:\n",
        "    print(\"No events found within the specified time window.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Summary and Interpretation\n",
        "\n",
        "### Key Findings:\n",
        "\n",
        "1. **Change Point Detection**: The Bayesian model identified a structural break in Brent oil prices.\n",
        "\n",
        "2. **Impact Quantification**: The model estimates the price level shifted from approximately $X to $Y, representing a Z% change.\n",
        "\n",
        "3. **Event Association**: The detected change point is temporally associated with [specific events], suggesting these events may have contributed to the structural break.\n",
        "\n",
        "4. **Uncertainty**: The posterior distributions provide probabilistic estimates with credible intervals, allowing for uncertainty quantification.\n",
        "\n",
        "### Limitations:\n",
        "\n",
        "- This analysis identifies **correlation**, not **causation**\n",
        "- The model assumes a single change point; multiple breaks may exist\n",
        "- External factors not included in the event dataset may also contribute\n",
        "- The timing of market impacts may differ from event dates (anticipation, delays)"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
